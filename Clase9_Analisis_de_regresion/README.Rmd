---
title: "Analisis de Regresion"
output: github_document
---

```{r setup, include=FALSE, message = FALSE, warning= FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Para el analisis de regresion vamos a utilizar datos de precios de viviendas en Santiago de Chile. Lo primero que haremos es cargar los datos y revisarlos con la funcion summary

```{r, message=  FALSE, warning= FALSE}
library(tidyverse)

propiedades <- read_csv("propiedades.csv")

summary(propiedades)
```
Vemos que en la base de datos se encuentran columnas del Precio de las viviendas, asi como la superficie de los terrenos, superficie construida, año de construccion, y algunas variables relativas al barrio, como densidad habitacional del barrio, y la presencia de colegios, jardines o lugares de trabajo a 15 minutos caminando de la ubicacion de la casa. 

Para comenzar buscaremos una relacion lineal entre el precio de la vivienda con los metros construidos. Antes de ejecutar la regresion inspeccionaremos los datos


```{r}
ggplot(propiedades, aes(Precio, Terreno)) + 
  geom_point()


```

Podemos ver que hay algunos datos atipicos que no reflejan el comportamiento esperado del mercado. Dado esto, los vamos a excluir del analisis.

```{r}
propiedades <- propiedades %>% filter(Terreno < 3000)

ggplot(propiedades, aes(Precio, Terreno)) + 
  geom_point() +
  geom_smooth(method = "lm")

```

Ahora ejecutaremos la regresion con las variables señaladas utilizando la funcion lm (linear model), que viene en R base

```{r}
regresion_lineal <- lm(Precio~Terreno, propiedades)

summary(regresion_lineal)
```

Los resultados de la regresion nos indican que los valores de los parametros son 770 para el intercepto y 10 para el coeficiente asociado a la variable superficie de terreno.

Tambien se puede observar que el coeficiente de determinacion R2 es de .41, lo que significa que el 41% de la varianza del precio esta explicada por el modelo lineal. 

El metodo de regresion lineal tambien permite obtener las desviaciones estandar de los parametros, y por lo tanto se puede calcular el estadistico t-student y el valor p. En la tabla resumen se puede ver que ambos parametros tienen significancia estadistica de 100%, lo que significa que aportan realmente en la explicacion del precio.

Puede suceder que la relacion entre ambas variables tenga un comportamiento logaritmico en lugar de lineal, por lo que vamos a probar esta hipotesis aplicando logaritmo natural en ambas variables

```{r}

regresion_log <- lm(log(Precio)~log(Terreno), propiedades)

summary(regresion_log)

```

Podemos ver que el coeficiente de determinacion mejoro a un 47% y que ambos coeficientes siguen siendo estadisticamente significativos, lo que significia que este es un mejor modelo que el anterior. 

Tambien es posible que la relacion entre ambas variables tenga una forma polinomica. Vamos a probar con un polinomio de orden 3. 

```{r}

propiedades$Terreno2 <- propiedades$Terreno^2
propiedades$Terreno3 <- propiedades$Terreno^3

regresion_poli <- lm(log(Precio) ~ Terreno + Terreno2 + Terreno3, propiedades)

summary(regresion_poli)

```

Se puede ver que la regresion polinomica tiene mejor coeficiente R2 que el modelo original, y que todos los coeficientes siguen siendo estadisticamente significativos. 

Hasta ahora solo hemos probado con una variable, vamos a ver si incluimos el resto de las variables presentes en la base de datos. 

```{r}

regresion_multi <- lm(Precio ~ Terreno+Construido+Año_Construccion+densidad_barrio+colegio_15m + jardin_15m + trabajo_15m , propiedades)

summary(regresion_multi)

```

Se puede ver que el modelo lineal multiple tiene un coeficiente de determinacion de 57%, y que hay algunas variables que tienen significancia estadistica menor a 99%, e incluso hay variables que no son relevantes en este modelo como el año de construccion. 

Esto no significa que el año no sea relevante, sino que no lo es en ESTE MODELO. 

Ahora vamos a probar diferentes metodos para determinar cual es la mejor combinacion de variables para el modelo lineal.

Los metodos de determinacion de modelos estan implementados en la libreria olsrr, y el primer metodo que probaremos es el de fuerza bruta

```{r, message=FALSE}
library(olsrr)

fuerza_bruta <- ols_step_all_possible(regresion_multi)

plot(fuerza_bruta)

```

Luego el metodo de seleccion hacia adelante
```{r}
sel_adelante <- ols_step_forward_p(regresion_multi)

sel_adelante


```

Y finalmente el metodo de  seleccion hacia atras
```{r}
sel_atras <- ols_step_backward_p(regresion_multi)

sel_atras

```



