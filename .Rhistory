simil = simil(list(x,y)),
median_x    = median(x),
median_y    = median(y),
CV_x = sd(x) / mean(x),
CV_y = sd(y) / mean(y),
max_x = max(x),
max_y = max(y)
)
stats <- datasaurus_dozen %>%
group_by(dataset) %>%
summarize(
mean_x    = mean(x),
mean_y    = mean(y),
std_dev_x = sd(x),
std_dev_y = sd(y),
corr_pears  = cor(x, y, method = "pearson"),
corr_spear  = cor(x, y, method = "spearman"),
corr_kendall  = cor(x, y, method = "kendall"),
simil = simil(list(x,y)),
median_x    = median(x),
median_y    = median(y),
CV_x = sd(x) / mean(x),
CV_y = sd(y) / mean(y),
max_x = max(x),
max_y = max(y)
)
? simil
summary(pr_DB)
stats <- datasaurus_dozen %>%
group_by(dataset) %>%
summarize(
mean_x    = mean(x),
mean_y    = mean(y),
std_dev_x = sd(x),
std_dev_y = sd(y),
corr_pears  = cor(x, y, method = "pearson"),
corr_spear  = cor(x, y, method = "spearman"),
corr_kendall  = cor(x, y, method = "kendall"),
simil_cos = simil(list(x,y), method = "cosine"),   # funcion simil en la libreria proxy
simil_jac = simil(list(x,y), method = "Jaccard"),   # funcion simil en la libreria proxy
simil_sm = simil(list(x,y), method = "simple matching"),   # funcion simil en la libreria proxy
simil_kul = simil(list(x,y), method = "Kulczynski1"),   # funcion simil en la libreria proxy
dist_euc = dist(list(x,y), method = "Euclidean"),
dist_manh = dist(list(x,y), method = "Manhattan"),
dist_sup = dist(list(x,y), method = "supremum"),
dist_mahal = dist(list(x,y), method = "Mahalanobis"),
median_x    = median(x),
median_y    = median(y),
CV_x = sd(x) / mean(x),
CV_y = sd(y) / mean(y),
max_x = max(x),
max_y = max(y)
)
stats <- datasaurus_dozen %>%
group_by(dataset) %>%
summarize(
mean_x    = mean(x),
mean_y    = mean(y),
std_dev_x = sd(x),
std_dev_y = sd(y),
corr_pears  = cor(x, y, method = "pearson"),
corr_spear  = cor(x, y, method = "spearman"),
corr_kendall  = cor(x, y, method = "kendall"),
simil_cos = simil(list(x,y), method = "cosine"),   # funcion simil en la libreria proxy
simil_jac = simil(list(x,y), method = "Jaccard"),   # funcion simil en la libreria proxy
simil_sm = simil(list(x,y), method = "simple matching"),   # funcion simil en la libreria proxy
simil_kul = simil(list(x,y), method = "Kulczynski1"),   # funcion simil en la libreria proxy
dist_euc = dist(list(x,y), method = "Euclidean"),
dist_manh = dist(list(x,y), method = "Manhattan"),
dist_sup = dist(list(x,y), method = "supremum"),
median_x    = median(x),
median_y    = median(y),
CV_x = sd(x) / mean(x),
CV_y = sd(y) / mean(y),
max_x = max(x),
max_y = max(y)
)
View(stats)
simil(list(datasaurus_dozen$x,datasaurus_dozen$y), method = "simple matching")
simil(list(datasaurus_dozen$x,datasaurus_dozen$y), method = "simple matching") %>% as.numeric()
stats <- datasaurus_dozen %>%
group_by(dataset) %>%
summarize(
mean_x    = mean(x),
mean_y    = mean(y),
std_dev_x = sd(x),
std_dev_y = sd(y),
corr_pears  = cor(x, y, method = "pearson"),
corr_spear  = cor(x, y, method = "spearman"),
corr_kendall  = cor(x, y, method = "kendall"),
simil_cos = simil(list(x,y), method = "cosine") %>% as.numeric(),   # funcion simil en la libreria proxy
simil_jac = simil(list(x,y), method = "Jaccard") %>% as.numeric(),   # funcion simil en la libreria proxy
simil_sm = simil(list(x,y), method = "simple matching") %>% as.numeric(),   # funcion simil en la libreria proxy
simil_kul = simil(list(x,y), method = "Kulczynski1") %>% as.numeric(),   # funcion simil en la libreria proxy
dist_euc = dist(list(x,y), method = "Euclidean") %>% as.numeric(),
dist_manh = dist(list(x,y), method = "Manhattan") %>% as.numeric(),
dist_sup = dist(list(x,y), method = "supremum") %>% as.numeric(),
median_x    = median(x),
median_y    = median(y),
CV_x = sd(x) / mean(x),
CV_y = sd(y) / mean(y),
max_x = max(x),
max_y = max(y)
)
stats %>% glimpse()
View(stats)
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset))+
geom_hist()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
library(ggplot2)
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset))+
geom_hist()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset))+
geom_histogram()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_histogram()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_histogram()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_density()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y = y, colour=dataset))+
geom_density2d()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y = dataset, colour=dataset))+
geom_boxplot()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, colour=dataset))+
geom_boxplot()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, colour=dataset))+
geom_violin()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset))+
geom_violin()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset))+
geom_point() +
theme_void() +
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, dataset=y, colour=dataset))+
geom_point() +
theme_void() +
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset))+
geom_point() +
theme_void() +
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset))+
geom_point() +
theme_void() +
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=1)
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset))+
geom_point() +
geom_boxplot() +
theme_void() +
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=1)
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset)) +
geom_point() +
geom_boxplot() +
theme_void() +
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset)) +
geom_point() +
geom_boxplot() +
theme_void() +
theme(legend.position = "none")
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset)) +
geom_point() +
geom_boxplot() +
geom_violin() +
theme_void() +
theme(legend.position = "none")
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset)) +
geom_point() +
geom_boxplot() +
theme_void() +
theme(legend.position = "none")
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset)) +
geom_point() +
geom_boxplot() +
geom_smooth() +
theme_void() +
theme(legend.position = "none")
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset)) +
geom_point() +
geom_boxplot() +
theme_void() +
theme(legend.position = "none")
# scatter
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset)) + # la primera linea define los parametros del grafico, la data, coordenadas y color
geom_point() +                                        # en esta linea se define la geometria de la figura, en este caso un punto
theme_void() +                                        # aca definimos el tema del grafico
theme(legend.position = "none") +                     # quitamos la leyenda
facet_wrap(~dataset, ncol=3)                          # creamos un subgrafico por cada dataset
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_histogram()+                                    # cambio la geometria
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_histogram(binwidth = 1)+                                    # cambio la geometria
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_histogram(binwidth = 2)+                                    # cambio la geometria
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
install.packages("FSinR")
install.packages("stuart")
knitr::opts_chunk$set(echo = TRUE)
library(stuart)
data(fairplayer)
fs <- list(ra = names(fairplayer)[53:57])
sel <- bruteforce(fairplayer, fs, 3,
cores = 1)  # number of cores set to 1
install.packages("lavan")
install.packages("lavaan")
data(fairplayer)
fs <- list(ra = names(fairplayer)[53:57])
sel <- bruteforce(fairplayer, fs, 3,
cores = 1)  # number of cores set to 1
summary(sel)  # Fit is perfect because of just-identified model
knitr::opts_chunk$set(echo = TRUE)
library(stuart)
data(fairplayer)
force(fairplayer)
View(fairplayer)
fs <- list(ra = names(fairplayer)[53:57])
library(FSinR)
library(FSinR)
```
data(iris)
force(iris)
data(iris)
fs <- list(ra = names(iris)[1:5])
library(stuart)
sel <- bruteforce(iris, fs, 3,
cores = 1)  # number of cores set to 1
data(iris)
iris$setosa <- ifelse(iris$Species == "setosa", 1, 0)
iris$virginica <- ifelse(iris$Species == "virginica", 1, 0)
iris$versicolor <- ifelse(iris$Species == "versicolor", 1, 0)
iris$Species
iris$versicolor <- ifelse(iris$Species == "versicolor", 1, 0)
iris$setosa
iris$virginica
iris$versicolor
str(iris)
iris$Species == NULL
iris$Species <- NULL
sel <- bruteforce(iris, names(iris), 3,cores = 1)
? bruteforce
sel <- bruteforce(iris, names(iris))
fs <- list(ra = names(iris)[1:5])
sel <- bruteforce(iris, fs, 3,
cores = 1)  # number of cores set to 1
fs <- list(ra = names(iris)[1:7])
sel <- bruteforce(iris, fs, 3,
cores = 1)  # number of cores set to 1
summary(sel)  # Fit is perfect because of just-identified model
evaluator <- wrapperEvaluator("knn")
sel <- bruteforce(iris, fs, 3,
cores = 4)  # numero de nucleos en la maquina
data(mtcars)
force(mtcars)
? filterEvaluator
filtro <- filterEvaluator('MDLC')
searcher <- searchAlgorithm('sequentialForwardSelection')
results <- featureSelection(iris, searcher, filtro)
? featureSelection
data(iris)
str(iris)
# debemos transformar variable Species en numerica, lo hacemos creando variables dummy
iris$setosa <- ifelse(iris$Species == "setosa", 1, 0)
iris$virginica <- ifelse(iris$Species == "virginica", 1, 0)
iris$versicolor <- ifelse(iris$Species == "versicolor", 1, 0)
seleccion_fuerza_bruta <- bruteforce(iris, list(ra = names(iris)[1:4,6:8]), 3,
cores = 4)  # numero de nucleos en la maquina
list(ra = names(iris)[1:4,6:8])
list(ra = names(iris)[c(1:4,6:8)])
seleccion_fuerza_bruta <- bruteforce(iris, list(ra = names(iris)[c(1:4,6:8)]), 3,
cores = 4)  # numero de nucleos en la maquina
?searchAlgorithm
? filterEvaluator
? wrapperEvaluator
evaluator <- wrapperEvaluator("mlpWeightDecay")
resultWrapper <- wrapper_evaluator(iris, 'Species', c("Petal.Length", "Petal.Width"))
resultWrapper <- evaluator(iris, 'Species', c("Petal.Length", "Petal.Width"))
? directSearchAlgorithm
searcher <- searchAlgorithm('sequentialForwardSelection')
searcher <- searchAlgorithm('geneticAlgorithm')
searcher <- searchAlgorithm('tabu', list(tamTabuList = 4, iter = 5, intensification=2, iterIntensification=5, diversification=1, iterDiversification=5, verbose=FALSE) )
searcher <- searchAlgorithm('antColony')
filtro <- filterEvaluator('MDLC')
filtro <- filterEvaluator("IEConsistency")
filtro <- filterEvaluator('determinationCoefficient')
filtro <- filterEvaluator('chiSquared')
? searchAlgorithm
# Para usarla, primero debemos utilizar un metodo de optimizacion, donde todas las opciones disponibles estan en
? searchAlgorithm
results <- featureSelection(iris, 'Species', searcher, filtro)
results <- featureSelection(iris, 'Species', searcher, filtro)
View(iris)
# Estos algoritmos buscaran el optimo en todo el espacio de soluciones
searcher <- searchAlgorithm('sequentialForwardSelection')
results <- featureSelection(iris, 'Species', searcher, filtro)
searcher <- searchAlgorithm('geneticAlgorithm')
results <- featureSelection(iris, 'Species', searcher, filtro)
filtro <- filterEvaluator('MDLC')
results <- featureSelection(iris, 'Species', searcher, filtro)
searcher <- searchAlgorithm('sequentialForwardSelection')
filtro <- filterEvaluator('MDLC')
results <- featureSelection(iris, 'Species', searcher, filtro)
evaluator <- wrapperEvaluator("knn")
evaluator <- wrapperEvaluator("xgbLinear")
evaluator <- wrapperEvaluator("lm")
evaluator <- wrapperEvaluator("svmLinearWeights")
evaluator <- wrapperEvaluator("mlpWeightDecay")
evaluator <- wrapperEvaluator("lvq")
results$bestFeatures
results
summary(results)
results$bestFeatures
evaluator <- wrapperEvaluator("lvq")
results <- featureSelection(iris, 'Species', searcher, evaluator)
results$bestFeatures
results$bestFeatures
## ojo que la funcion es diferente a la anterior
results <- directFeatureSelection(mtcars, 'mpg', directSearcher, evaluator)
directSearcher <- directSearchAlgorithm('selectKBest', list(k=3))
## ojo que la funcion es diferente a la anterior
results <- directFeatureSelection(mtcars, 'mpg', directSearcher, evaluator)
evaluator <- wrapperEvaluator("mlpWeightDecay")
## ojo que la funcion es diferente a la anterior
results <- directFeatureSelection(mtcars, 'mpg', directSearcher, evaluator)
results$bestFeatures
PCA <- prcomp(iris)
PCA <- prcomp(iris[,-c("Species")])
#PCA
iris$Species <- NULL
PCA <- prcomp(iris)
PCA$sdev
plot(PCA$sdev)
barplot(PCA$sdev)
fit <- cmdscale(d,eig=TRUE, k=2) # k is the number of dim
fit <- cmdscale(iris,eig=TRUE, k=2) # k is the number of dim
d <- dist(iris) # distancias euclidianas entre entidades
fit <- cmdscale(d,eig=TRUE, k=2) # k is the number of dim
fit
predict(PCA)
library(MASS)
nMDS <- isoMDS(d, k=2)
d <- dist(unique(iris)) # distancias euclidianas entre entidades
nMDS <- isoMDS(d, k=2)
nMDS$points
library(M3C)
install.packages("M3C")
library(M3C)
library(Rtsne)
install.packages("Rtsne")
library(Rtsne)
tsne <- Rtsne(iris, dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
data(iris)
data(iris) %>% unique()
library(tidyverse)
data(iris) %>% unique()
iris <- iris %>% unique()
iris_num <- iris
iris_num$Species <- NULL
tsne <- Rtsne(iris_num, dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
tsne$Y
predict(PCA)
predict(PCA) %>% ggplot(aes(PC1,PC2)) + geom_point()
predict(PCA) %>% as.data.frame() %>%  ggplot(aes(PC1,PC2)) + geom_point()
predict(PCA) %>% as.data.frame() %>%  ggplot(aes(PC1,PC2, col=iris$Species)) + geom_point()
iris <<- iris %>% unique()
iris_unicos <- iris %>% unique()
predict(PCA) %>% as.data.frame() %>%  ggplot(aes(PC1,PC2, col=iris0$Species)) + geom_point()
data(iris)
iris0 <- iris %>% unique()
iris0 <- iris %>% unique()
iris0 <- iris %>% unique()
str(iris0)
# debemos transformar variable Species en numerica, lo hacemos creando variables dummy
iris0$setosa <- ifelse(iris0$Species == "setosa", 1, 0)
iris0$virginica <- ifelse(iris0$Species == "virginica", 1, 0)
iris0$versicolor <- ifelse(iris0$Species == "versicolor", 1, 0)
iris_num <- iris0 # creamos una copia de la data pero con varibles numericas solamente
iris_num$Species <- NULL
## primero probaremos el algoritmo de fuerza bruta
library(stuart)
results <- bruteforce(iris_num, list(ra = names(iris_num)), 3,
cores = 4)  # numero de nucleos en la maquina
summary(results)
## para el resto de los metodos utilizamos la siguiente libreria
library(FSinR)   # feature selection
# Para usarla, primero debemos utilizar un metodo de optimizacion, donde todas las opciones disponibles estan en
? searchAlgorithm
# Estos algoritmos buscaran el optimo en todo el espacio de soluciones
searcher <- searchAlgorithm('geneticAlgorithm')
searcher <- searchAlgorithm('tabu', list(tamTabuList = 4, iter = 5, intensification=2, iterIntensification=5, diversification=1, iterDiversification=5, verbose=FALSE) )
searcher <- searchAlgorithm('antColony')
searcher <- searchAlgorithm('sequentialForwardSelection')
## Luego tenemos que definir una variable para filtrar, las variables disponibles estan en
? filterEvaluator
filtro <- filterEvaluator("IEConsistency")
filtro <- filterEvaluator('determinationCoefficient')
filtro <- filterEvaluator('chiSquared')
filtro <- filterEvaluator('MDLC')
## finalmente optimizamos los atributos, utilizando la variable Species como referencia para pronosticar
results <- featureSelection(iris0, 'Species', searcher, filtro)
results$bestFeatures
## tambien se puede pronosticar la variable de referencia utilizando una funcion de envoltorio o wrapper. las funciones disponibles se pueden ver en
? wrapperEvaluator
evaluator <- wrapperEvaluator("knn")
evaluator <- wrapperEvaluator("xgbLinear")
evaluator <- wrapperEvaluator("lm")
evaluator <- wrapperEvaluator("svmLinearWeights")
evaluator <- wrapperEvaluator("mlpWeightDecay")
results <- featureSelection(iris0, 'Species', searcher, evaluator)
evaluator <- wrapperEvaluator("lm")
? searchAlgorithm
searcher <- searchAlgorithm('hillClimbing')
## finalmente optimizamos los atributos, utilizando la variable Species como referencia para pronosticar
results <- featureSelection(iris0, 'Species', searcher, filtro)
results$bestFeatures
## tambien se puede pronosticar la variable de referencia utilizando una funcion de envoltorio o wrapper. las funciones disponibles se pueden ver en
? wrapperEvaluator
evaluator <- wrapperEvaluator("knn")
evaluator <- wrapperEvaluator("xgbLinear")
evaluator <- wrapperEvaluator("svmLinearWeights")
evaluator <- wrapperEvaluator("mlpWeightDecay")
evaluator <- wrapperEvaluator("lm")
results <- featureSelection(iris0, 'Species', searcher, evaluator)
evaluator <- wrapperEvaluator("svmLinearWeights")
results <- featureSelection(iris0, 'Species', searcher, evaluator)
evaluator <- wrapperEvaluator("knn")
results <- featureSelection(iris0, 'Species', searcher, evaluator)
results$bestFeatures
directSearcher <- directSearchAlgorithm('selectKBest', list(k=3))
## ojo que la funcion es diferente a la anterior
results <- directFeatureSelection(iris0, 'Species', directSearcher, evaluator)
results$bestFeatures
#PCA
PCA <- prcomp(iris_num)
barplot(PCA$sdev)
predict(PCA) %>% as.data.frame() %>%  ggplot(aes(PC1,PC2, col=iris0$Species)) + geom_point()
library(GGally)
ggpairs(iris_num)
ggpairs(iris_num, aes(col=iris0$Species))
d <- dist(iris_num) # distancias euclidianas entre entidades
MDS <- cmdscale(d,eig=TRUE, k=2) # k es el numero de dimensiones de salida
MDS$points
MDS$points %>%  ggplot(aes( col=iris0$Species)) + geom_point()
MDS$points %>% as.data.frame()
MDS$points %>% as.data.frame() %>% colnames()
MDS$points %>% as.data.frame() %>% ggplot(aes(V1,V2, col=iris0$Species)) + geom_point()
nMDS$points %>% as.data.frame() %>% ggplot(aes(V1,V2, col=iris0$Species)) + geom_point()
library(MASS)
nMDS <- isoMDS(d, k=2)
nMDS$points %>% as.data.frame() %>% ggplot(aes(V1,V2, col=iris0$Species)) + geom_point()
library(Rtsne)
tsne <- Rtsne(iris_num, dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
tsne$Y
tsne$Y %>% as.data.frame() %>% ggplot(aes(V1,V2, col=iris0$Species)) + geom_point()
photo <- readJPEG("Imagen1.jpg")
library(jpeg)
photo <- readJPEG("Imagen1.jpg")
plot(photo)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
tsne <- Rtsne(iris_num, dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
library(Rtsne)
Rtsne
? Rtsne
library(stuart)
? bruteforce
