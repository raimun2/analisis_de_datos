#Hierarchical
d = dist(data_escalada)
#Applying the model
model = hclust(d, method="complete") #complete, average could also be use
? hclust
model_ward = hclust(d, method="ward.D")
model_complete = hclust(d, method="complete")
model_ward = hclust(d, method="ward.D")
model_ward2 = hclust(d, method="ward.D2")
model_single = hclust(d, method="single")
model_average = hclust(d, method="average")
model_mcquitty = hclust(d, method="mcquitty")
model_median = hclust(d, method="median")
model_centroid = hclust(d, method="centroid")
ggdendrogram(model_complete, rotate=F,theme_dendro = T,labels = F)+theme(axis.text.y = element_text(size=5))+scale_y_continuous(breaks=seq(0,60,5))
library("ggdendro")
ggdendrogram(model_complete, rotate=F,theme_dendro = T,labels = F)+theme(axis.text.y = element_text(size=5))+scale_y_continuous(breaks=seq(0,60,5))
plot(model_complete)
ggdendrogram(model_complete)
##############################################################################
library(fclust)
? FKM
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales) %>%
select(c(6:9, 10, 12)) %>%
scale() %>%
as_tibble()
#Hierarchical
d = dist(data_escalada)
#Applying the model
model_complete = hclust(d, method="complete")
model_ward = hclust(d, method="ward.D")
model_ward2 = hclust(d, method="ward.D2")
model_single = hclust(d, method="single")
model_average = hclust(d, method="average")
model_mcquitty = hclust(d, method="mcquitty")
model_median = hclust(d, method="median")
model_centroid = hclust(d, method="centroid")
ggdendrogram(model_complete)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales) %>%
select(c(6:9, 10, 12)) %>%
scale() %>%
as_tibble()
data_escalada %>% head()
knitr::opts_chunk$set(echo = TRUE)
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales) %>%
select(c(6:9, 10, 12)) %>%
scale() %>%
as_tibble()
#Distancia euclideana
d = dist(data_escalada)
hist(dist)
hist(d)
model_complete = hclust(d, method="complete")
(model_complete = hclust(d, method="complete") )
summary(model_complete)
summary(model_complete)
model_complete = hclust(d, method="complete")
model_complete = hclust(d, method="complete")
summary(model_complete)
? ggdendrogram
library("ggdendro")
? ggdendrogram
ggdendrogram(model_complete, rotate = TRUE, theme_dendro = TRUE)
? hclust
groups <- cutree(model, h=5)
groups <- cutree(model_complete, h=5)
coefSil <- silhouette(groups, d)
library(cluster)
coefSil <- silhouette(groups, d)
summary(coefSil)
mean(coefSil)
model_complete$height
model_complete$height %>% table()
model_complete$height %>% summary()
summary(coefsil)
coefsil <- silhouette(groups, d)
summary(coefsil)
groups %>% unique() %>% length()
mean(coefsil)
groups <- cutree(model_complete, h = 3)
coefsil <- silhouette(groups, d)
groups %>% unique() %>% length()
groups <- cutree(model_complete, h = 50)
coefsil <- silhouette(groups, d)
groups %>% unique() %>% length()
max(d)
groups %>% unique() %>% length()
mean(coefsil)
summary(coefsil)
res <- numeric(70)
for (i in 1:70){
groups <- cutree(model_complete, h = i)
coefsil <- silhouette(groups, d)
groups %>% unique() %>% length()
numeric[i] <- mean(coefsil)
}
groups <- cutree(model_complete, h = i)
coefsil <- silhouette(groups, d)
mean(coefsil)
numeric[i]
#groups %>% unique() %>% length()
res[i] <- mean(coefsil)
for (i in 1:70){
groups <- cutree(model_complete, h = i)
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res[i] <- mean(coefsil)
}
plot(res)
log(70)
(1:40)/10
exp((1:40)/10 )
exp((0:40)/10 )
exp((-1:40)/10 )
exp((-10:40)/10 )
exp((-30:40)/10 )
res <- exp((-30:40)/10)
res$sil <- 0
res <- exp((-30:40)/10)
res <- exp((-30:40)/10) %>% tibble()
res$sil <- 0
View(res)
res <- tibble("h" = exp((-30:40)/10))
res$sil <- 0
View(res)
for (i in 1:71){
groups <- cutree(model_complete, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
plot(res)
res <- tibble("h" = quantile(d, q = 1:100))
View(res)
? quantile
res <- tibble("h" = quantile(d, probs  = 1:100))
res <- tibble("h" = quantile(d, probs  = (1:100)/100))
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
View(res)
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
ggplot(res, aes(log(h), sil)) +
geom_line()
ggplot(res, aes(log(h), sil)) +
geom_point()
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_ward, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
model_ward = hclust(d, method="ward.D")
model_ward2 = hclust(d, method="ward.D2")
model_single = hclust(d, method="single")
model_average = hclust(d, method="average")
model_mcquitty = hclust(d, method="mcquitty")
model_median = hclust(d, method="median")
model_centroid = hclust(d, method="centroid")
summary(model_ward)
summary(model_ward2)
summary(model_single)
summary(model_average)
summary(model_mcquitty)
summary(model_median)
summary(model_centroid)
for (i in 1:100){
groups <- cutree(model_ward, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
ggplot(res, aes(log(h), sil)) +
geom_point()
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_ward2, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
ggplot(res, aes(log(h), sil)) +
geom_point()
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_single, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
ggplot(res, aes(log(h), sil)) +
geom_point()
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_mcquitty, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
ggplot(res, aes(log(h), sil)) +
geom_point()
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_median, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_centroid, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_average, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
for (i in 1:100){
groups <- cutree(model_average, h = res$h[i])
coefsil <- silhouette(groups, d)
#groups %>% unique() %>% length()
res$sil[i] <- mean(coefsil)
}
ggplot(res, aes(log(h), sil)) +
geom_point()
ggplot(res, aes((h), sil)) +
geom_point()
ggplot(res, aes(log(h), sil)) +
geom_point()
res <- tibble("h" = quantile(d, probs  = (1:100)/100), sil = 0)
for (i in 1:100){
groups <- cutree(model_average, h = res$h[i])
res$sil[i] <- groups %>% unique() %>% length()
}
for (i in 1:100){
groups <- cutree(model_average, h = res$h[i])
res$sil[i] <- groups %>% unique() %>% length()
}
ggplot(res, aes(log(h), sil)) +
geom_point()
ggplot(res, aes(h, sil)) +
geom_point()
ggplot(res, aes(log(h), sil)) +
geom_point()
ggplot(res, aes(h, sil)) +
geom_point() +
scale_x_log10()
ggplot(res, aes(h, sil)) +
geom_point() +
scale_x_log10() +
scale_y_log10()
library(tidyverse)
data <- data.frame("var1" = 1:100, "var2" = rnorm(100))
View(data)
table(data$var1)
summary(data)
data %>% summary()
data %>% mean() %>% sum()
? quantile
quantile(data$var2, probs = 0.5)
median(data$var2)
quantile(data$var2)
(1:100)/100
1:100
(1:100)/100
quantile(data$var2, probs = (1:100)/100)
knitr::opts_chunk$set(echo = TRUE)
##############################################################################
library(mclust)
? mclust
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales) %>%
select(c(6:9, 10, 12)) %>%
scale() %>%
as_tibble()
library(tidyverse)
library(tidyverse)
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales) %>%
select(c(6:9, 10, 12)) %>%
scale() %>%
as_tibble()
data_escalada %>% head()
#DBSCAN
#install.packages("dbscan")
library(dbscan)
model = dbscan(data_escalada, eps = 0.2, minPts = 5)
model
ggplot(data_escalada, aes(NA_Sales, User_Score, color = factor(model$cluster))) + geom_point()+theme(axis.text=element_text(size=12),axis.title=element_text(size=18))
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) + geom_point()+theme(axis.text=element_text(size=12),axis.title=element_text(size=18))
model
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) +
geom_point() +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
data_pc <- data_escalada %>% prcomp() %>% predict() %>% select(PC1, PC2)
data_pc <- data_escalada %>% prcomp() %>% predict() %>% as.data.frame() %>% select(PC1, PC2)
View(data_pc)
ggplot(data_pc, aes(PC1, PC2, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
data_pc <- data_escalada %>% prcomp() %>% predict() %>% as.data.frame() %>% select(PC1, PC8)
data_pc <- data_escalada %>% prcomp() %>% predict() %>% as.data.frame() %>% select(PC1, PC5)
ggplot(data_pc, aes(PC1, PC5, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
library(fclust)
coefSil <- numeric(50)
coefSil <- numeric(50)
for (i in 1:50){
temp <- FKM(data_escalada, i, m=3)
coefSil[i] <- temp$criterion
}
temp <- FKM(data_escalada, 10, m=3)
library(e1071)
modelo_c_means1 <- FKM(data_escalada, 10, m=3)
modelo_c_means2 <- cmeans(data_escalada, 10, m=3)
modelo_c_means1 <- FKM(data_escalada, 10, m=3)
modelo_c_means$memership
modelo_c_means <- cmeans(data_escalada, 10, m=3)
modelo_c_means$memership
modelo_c_means$membership
modelo_c_means$membership %>% head()
#Trace of the cluster
matriz <- modelo_c_means$U%*%t(modelo_c_means$U) #matrix multiplication
temp <- FKM(data_escalada, 10, m=3)
temp$U
#Trace of the cluster
matriz <- modelo_c_means$membership%*%t(modelo_c_means$membership) #matrix multiplication
modelo_c_means <- cmeans(data_escalada, 10, m=3)
modelo_c_means <- cmeans(data_escalada, 10, m=3)
modelo_c_means$membership %>% head()
sum(matriz*diag(nrow(matriz)))/nrow(matriz)
FPC <- sum(matriz*diag(nrow(matriz)))/nrow(matriz)
modelo_c_means$clus
modelo_c_means$clus[,1]
ggplot(data_escalada) +
aes(x=Critic_Score,y=User_Score,color=factor(modelo_c_means$clus)) +
geom_point(alpha=0.5,show.legend = F) +
theme_bw()
(FPC <- sum(matriz*diag(nrow(matriz)))/nrow(matriz))
library(mclust)
#Training the model
model = Mclust(data_escalada)
summary(model)
#Assignations
model$z
model$classification
data[model$classification==9,1]
plot(model)
#Assignations
model$z
ggplot(data)+
aes(x=Critic_Score, y=User_Score, color=factor(model$classification)) +
geom_point(alpha=0.5,show.legend = F) +
theme_bw()
#Training the model
model = Mclust(data_escalada)
? mclust::plot
plot(model)
plot(model, 2)
plot(model, x = BIC)
plot(model, x = "BIC")
plot(model, what = "BIC")
plot(model, what = "AIC")
plot(model, what = "classification")
plot(model, what = "uncertainty")
#AIC BIC
plot(model, what = "BIC")
ggplot(data_escalada) +
aes(x=Critic_Score, y=User_Score, color=factor(model$classification)) +
geom_point(alpha=0.5, show.legend = F) +
theme_bw()
```{r, message = FALSE, warning = FALSE}
```{r}
model = dbscan(data_escalada, eps = 0.2, minPts = 5)
model
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales, Critic_Score, User_Score) %>%
select(c(6:9, 10, 12)) %>%
scale() %>%
as_tibble()
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales, Critic_Score, User_Score) %>%
#select(c(6:9, 10, 12)) %>%
scale() %>%
as_tibble()
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales) %>%
select(Critic_Score, User_Score) %>%
scale() %>%
as_tibble()
library(tidyverse)
data_escalada  <- read.csv("video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(-Global_Sales) %>%
select(Critic_Score, User_Score) %>%
scale() %>%
as_tibble()
data_escalada %>% head()
data_escalada %>% summary()
library(dbscan)
model = dbscan(data_escalada, eps = 0.2, minPts = 5)
model
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
model = dbscan(data_escalada, eps = 0.1, minPts = 5)
model
model = dbscan(data_escalada, eps = 0.15, minPts = 5)
model
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
model = dbscan(data_escalada, eps = 0.15, minPts = 15)
model
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
library(e1071)
modelo_c_means <- cmeans(data_escalada, 10, m=3)
model = dbscan(data_escalada, eps = 0.1, minPts = 15)
model
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(model$cluster))) +
geom_point(alpha = 0.3) +
theme(axis.text = element_text(size=12), axis.title = element_text(size = 18))
modelo_c_means <- cmeans(data_escalada, 16, m=3)
modelo_c_means$membership %>% head()
modelo_c_means$cluster
modelo_c_means$membership %>% head()
ggplot(data_escalada, aes(Critic_Score, User_Score, color = factor(modelo_c_means$cluster))) +
geom_point(alpha = 0.3)
modelo_c_means$membership %>% head()
matriz <- modelo_c_means$membership%*%t(modelo_c_means$membership) # producto matricial
matriz <- modelo_c_means$membership%*%t(modelo_c_means$membership) # producto matricial
(FPC <- sum(matriz*diag(nrow(matriz)))/nrow(matriz))
#Training the model
model = Mclust(data_escalada)
ggplot(data_escalada) +
aes(x=Critic_Score, y=User_Score, color=factor(model$classification)) +
geom_point(alpha=0.5, show.legend = F) +
theme_bw()
ggplot(data_escalada) +
aes(x=Critic_Score, y=User_Score, color=factor(model_gmm$classification)) +
geom_point(alpha=0.5)
#Training the model
model_gmm = Mclust(data_escalada)
matriz <- model_gmm$classification%*%t(model_gmm$classification) # producto matricial
(FPC <- sum(matriz*diag(nrow(matriz)))/nrow(matriz))
model_gmm$classification
modelo_c_means$membership
model_gmm$uncertainty
model_gmm$data
model_gmm$z
ggplot(data_escalada) +
aes(x=Critic_Score, y=User_Score, color=factor(model_gmm$classification)) +
geom_point(alpha=0.5)
model_gmm
model_gmm %>% summary()
model_gmm
? Mclust
summary(model_gmm, parameters = TRUE)
summary(model_gmm)
summary(model_gmm, parameters = TRUE)
El modelo genero 5 clusters los que se pueden visualizar igual que los ejemplos anteriores
```{r}
ggplot(data_escalada) +
aes(x=Critic_Score, y=User_Score, color=factor(model_gmm$classification)) +
geom_point(alpha=0.5)
plot(model, what = "BIC")
ggplot(data_escalada) +
aes(x=Critic_Score, y=User_Score, color=factor(model_gmm$classification)) +
geom_point(alpha=0.5)
plot(model_gmm, what = "BIC")
(FPC <- sum(matriz*diag(nrow(matriz)))/nrow(matriz))
