plot(model)
#Training a network wiht a single neuron in the hidden layer
prod_model <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,
data = train,linear.output = F)
plot(prod_model)
model_results <- compute(prod_model, test[,c(1,6:9)])
predicted_prod <- model_results$net.result
CM=table(test$ProdMayorUbral,predicted_prod>0.5) #confusion matrix
CM
#Increasing the number of neurons
prod_model2 <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,
data = train,hidden =4,linear.output = F)
plot(prod_model2)
model_results2 <- compute(prod_model2, test[,c(1,6:9)])
predicted_prod2 <- model_results2$net.result
CM=table(test$ProdMayorUbral,predicted_prod2>0.5) #confusion matrix
CM
#Increasin the number of layer
prod_model3 <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,
data = train,hidden =c(4,3),linear.output = F)
plot(prod_model3)
model_results3 <- compute(prod_model3, test[,c(1,6:9)])
predicted_prod3 <- model_results3$net.result
CM=table(test$ProdMayorUbral,predicted_prod3>0.15) #confusion matrix
CM
##########################################################
##################Neural Network##########################
##########################################################
require(utils)
library(rpart)
library(ggplot2)
#Fast example
library(RSSL)
data=generateCrescentMoon(1000,2,2)
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
ggplot(data)+aes(x=X1,y=X2,fill=Class)+theme_void()+
geom_point(shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
#Using perceptron
library(neuralnet)
test=expand.grid(X1 = seq(-14, 14, 0.1), X2 = seq(-14, 14, 0.1))
data$newOutput=as.numeric(data$Class=="+")
model <- neuralnet(newOutput ~ X1 + X2,hidden=0,data = data,linear.output = F)
plot(model)
output=compute(model, test[,c(1,2)])
test$Class=1-output$net.result
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
ggplot()+theme_void()+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
ggplot()+theme_void()+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
#Using neural network
data$newOutput=as.numeric(data$Class=="+")
model <- neuralnet(newOutput ~ X1 + X2,hidden=1,data = data,linear.output = F)
plot(model)
output=compute(model, test[,c(1,2)])
test$Class=1-output$net.result
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
ggplot()+theme_void()+
#  geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradient(low="red",high="blue")+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
#Using neural network
data$newOutput=as.numeric(data$Class=="+")
model <- neuralnet(newOutput ~ X1 + X2,hidden=1,data = data,linear.output = F)
plot(model)
output=compute(model, test[,c(1,2)])
test$Class=1-output$net.result
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
ggplot()+theme_void()+
#  geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradient(low="red",high="blue")+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
#Using neural network
data$newOutput=as.numeric(data$Class=="+")
model <- neuralnet(newOutput ~ X1 + X2,hidden=2,data = data,linear.output = F)
plot(model)
output=compute(model, test[,c(1,2)])
test$Class=1-output$net.result
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
ggplot()+theme_void()+
#  geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradient(low="red",high="blue")+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
model <- neuralnet(newOutput ~ X1 + X2,hidden=5,data = data,linear.output = F)
plot(model)
output=compute(model, test[,c(1,2)])
test$Class=1-output$net.result
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
ggplot()+theme_void()+
#  geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradient(low="red",high="blue")+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
model <- neuralnet(newOutput ~ X1 + X2,hidden=10,data = data,linear.output = F)
plot(model)
output=compute(model, test[,c(1,2)])
test$Class=1-output$net.result
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
plot(model)
ggplot()+theme_void()+
#  geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradient(low="red",high="blue")+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
model <- neuralnet(newOutput ~ X1 + X2,hidden=20,data = data,linear.output = F)
plot(model)
plot(model)
model <- neuralnet(newOutput ~ X1 + X2,hidden=20,data = data,linear.output = F)
plot(model)
output=compute(model, test[,c(1,2)])
test$Class=1-output$net.result
fillVector=rep("red",1000)
fillVector[1001:2000]="blue"
ggplot()+theme_void()+
#  geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradient(low="red",high="blue")+
geom_tile(aes(x=test$X1,y=test$X2,fill=test$Class),alpha=0.7,show.legend = F)+scale_fill_gradientn(colors=c("red","white","blue"),values=c(0,0.5,1))+
geom_point(aes(x=data$X1,y=data$X2,fill=Class),shape=21,fill=fillVector,show.legend = F)+
scale_x_continuous(limits = c(-14,14))+scale_y_continuous(limits = c(-14,14))
#Getting the current path and reading the data
getwd()
setwd("/Users/smorenoa/Google Drive/UAI/clasesUAI/2020-Mineria de Datos/codigoR")
data<-read.csv("CallCenterData.csv",header = TRUE,sep=";")
ccdata<-data[,-1]
#Defining a function to normlaize between 0 and 1
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
ccdata[,c(1,6:9,11)] <- as.data.frame(lapply(ccdata[,c(1,6:9,11)], normalize))
#splitting the data
sub <- sample(nrow(ccdata), floor(nrow(ccdata) * 0.7))
train<-ccdata[sub, ] #training 70 %
test<-ccdata[-sub, ] #test 30%
#########################################################
#################### Perceptron #########################
#########################################################
#installing and loading the library for neurtal networks
#install.packages("neuralnet")
library(neuralnet)
train$newOutput=train$ProdMayorUbral=="si"
train$newOutput
model <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,hidden=0,
data = train,linear.output = F)
model
plot(model)
plot(model)
#Observing the output of the entire network
output=compute(model, test[,c(1,6:9)])
output
CM=table(test$ProdMayorUbral,output$net.result>0.5) #confusion matrix
CM
#Training a network wiht a single neuron in the hidden layer
prod_model <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,
data = train,linear.output = F)
plot(prod_model)
#Increasing the number of neurons
prod_model2 <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,
data = train,hidden=4,linear.output = F)
plot(prod_model2)
model_results2 <- compute(prod_model2, test[,c(1,6:9)])
predicted_prod2 <- model_results2$net.result
CM=table(test$ProdMayorUbral,predicted_prod2>0.5) #confusion matrix
CM
#Increasin the number of layer
prod_model3 <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,
data = train,hidden =c(4,3),linear.output = F)
#Increasin the number of layer
prod_model3 <- neuralnet(newOutput ~ Edad + HorasLogeadas
+ HorasHabladas + ContactosEfectivosPromedio + RegistrosTerminados,
data = train,hidden =c(4,3),linear.output = F)
model_results3 <- compute(prod_model3, test[,c(1,6:9)])
predicted_prod3 <- model_results3$net.result
CM=table(test$ProdMayorUbral,predicted_prod3>0.15) #confusion matrix
CM
plot(prod_model3)
#Getting the current path and reading the data
getwd()
setwd("/Users/smorenoa/Google Drive/UAI/clasesUAI/2020-Mineria de Datos/codigoR/Predictions")
data<-read.csv("Churn_Modelling.csv",header = T)
data[,11]=factor(data[,11])
data[,12]=factor(data[,12])
#Tenure: Number of years for which the customer has been with the bank
trainData=data[1:8000,]
testData=data[8001:10000,]
#################################################################
#################### NeuralNetwork ##############################
#################################################################
#loading library for neural network
library(neuralnet)
model <- neuralnet(Exited~RowNumber+CustomerId,hidden=1,data = trainData,linear.output = F)
pred=compute(model, testData[,c(1,2)])
pred
#F1-score, varies between 0 and 1, 1 is better
result=as.numeric(pred$net.result>0.5)
temp=result+testData[,ncol(testData)]
TP=sum(temp==2)
FPFN=sum(temp==1)
2*TP/(2*TP+FPFN)
trainData
trainData$Geography
?neyralnet
?neuralnet
model <- neuralnet(Exited~RAge+NumOfProducts,hidden=3,data = trainData,linear.output = F)
#Getting the current path and reading the data
getwd()
setwd("/Users/smorenoa/Google Drive/UAI/clasesUAI/2020-Mineria de Datos/codigoR/Predictions")
data<-read.csv("Churn_Modelling.csv",header = T)
data[,11]=factor(data[,11])
data[,12]=factor(data[,12])
#Tenure: Number of years for which the customer has been with the bank
trainData=data[1:8000,]
testData=data[8001:10000,]
#################################################################
#################### NeuralNetwork ##############################
#################################################################
#loading library for neural network
library(neuralnet)
model <- neuralnet(Exited~Age+NumOfProducts,hidden=3,data = trainData,linear.output = F)
#################################################################
#################### NeuralNetwork ##############################
#################################################################
#loading library for neural network
library(neuralnet)
model <- neuralnet(Exited~Age+NumOfProducts,hidden=3,data = trainData,linear.output = T)
model <- neuralnet(Exited~Age+NumOfProducts,hidden=3,data = trainData,linear.output = T)
pred=compute(model, testData[,c(7,10)])
#F1-score, varies between 0 and 1, 1 is better
result=as.numeric(pred$net.result>0.3)
temp=result+testData[,ncol(testData)]
TP=sum(temp==2)
FPFN=sum(temp==1)
2*TP/(2*TP+FPFN)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("Churn_Modelling.csv",header = T)
library(tidyverse)
library(tidyverse)
ata <- read.csv("Churn_Modelling.csv",header = T)
ata %>% glimpse()
```{r, message=FALSE, warning= FALSE}
library(tidyverse)
data <- read.csv("Churn_Modelling.csv",header = T)
data %>% glimpse()
sample <- sample_frac(1:nrow(data), .8)
data <- read_csv("Churn_Modelling.csv",header = T)
data <- read_csv("Churn_Modelling.csv")
data %>% glimpse()
sample <- sample_frac(1:nrow(data), .8)
sample <- sample(1:nrow(data), .8*10000)
trainData <- data[sample,]
testData <- data[-sample,]
#loading library e1071
library(e1071)
? naiveBayes
data$is_female <- (data$Gender == "Female") %>% as.numeric()
data$RowNumber <- NULL
data$Surname <- NULL
data$Geography <- NULL
data$is_female <- (data$Gender == "Female") %>% as.numeric()
data$Gender <- NULL
trainData <- data[sample,]
testData <- data[-sample,]
model <- naiveBayes(Exited ~ ., data = trainData)
pred <- predict(model,testData, type="raw")
modeloNB <- naiveBayes(Exited ~ ., data = trainData)
pred <- predict(model,testData, type="raw")
pred <- predict(model,testData, type="raw")
plot(modeloNB)
table(pred, data$Exited)
pred <- predict(model,testData, type="raw")
table(pred, data$Exited)
pred <- predict(model,testData)
table(pred, data$Exited)
table(pred, testData$Exited)
table(pred, testData$Exited)
pred <- predict(model,testData, type="raw")
table(pred, testData$Exited)
table(pred, trainData$Exited)
modeloNB
#F1-score, varies between 0 and 1, 1 is better
result=as.numeric(pred[,2]>0.5)
temp=as.numeric(result)+testData[,ncol(testData)]
TP=sum(temp==2)
FPFN=sum(temp==1)
2*TP/(2*TP+FPFN)
library(pROC)
prob <- predict(modeloNB,type=c("response"))
prob <- predict(modeloNB,type=c("raw"))
prob <- predict(modeloNB,type=c("raw"))
prob <- predict(modeloNB, testData, type=c("raw"))
testData$prob <- pred
curva_roc <- roc(Exited ~ prob, data = testData)
pred <- predict(model,testData)
pred <- predict(model,testData)
pred <- predict(model,testData, type="class")
pred <- predict(model,testData, type="raw")
modeloNB <- naiveBayes(Exited ~ ., data = trainData)
pred <- predict(modeloNB,testData, type="class")
modeloNB <- naiveBayes(Exited ~ ., data = trainData)
pred <- predict(modeloNB,testData, type="class")
pred <- predict(modeloNB,testData, type="raw")
modeloNB <- naiveBayes(Exited ~ ., data = trainData)
pred <- predict(modeloNB, testData)
pred <- predict(modeloNB, testData[,-c("Exited")])
testData[,-c("Exited")]
testData[,!c("Exited")]
pred <- predict(modeloNB)
modeloNB <- naiveBayes(Exited ~ ., data = trainData)
trainData <- data[sample,]
testData <- data[-sample,]
modeloNB <- naiveBayes(Exited ~ ., data = trainData)
pred <- predict(modeloNB, testData)
modeloNB
testData$prob <- pred
predict(modeloNB, testData)
testData <- data[-sample,]
pred <- predict(modeloNB, testData, type ="raw")
pred <- predict(modeloNB, testData, type ="class")
pred <- predict(modeloNB, testData, type ="raw")
modeloNB
testData$prob <- pred[,2]
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
? knn
testData$prob <- NULL
modeloknn <- knn(trainData, testData, k = 3, prob = TRUE)
library(class)
modeloknn <- knn(trainData, testData, k = 3, prob = TRUE)
modeloknn <- knn(trainData, testData, cl =TRUE, k = 3, prob = TRUE)
modeloknn <- knn(trainData, testData, cl = factor(trainData$Exited), k = 3, prob = TRUE)
modeloknn
modeloknn %>%  summary()
modeloknn[,2]
modeloknn
modeloknn[1]
modeloknn[2]
testData$prob <- modeloknn
curva_roc <- roc(Exited ~ prob, data = testData)
testData$prob <- modeloknn %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
modeloknn
modeloknn %>% as.numeric()
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
modeloknn %>% as.character() %>% as.numeric()
modeloknn <- knn(trainData, testData, cl = factor(trainData$Exited), k = 3, prob = FALSE)
modeloknn <- knn(trainData, testData, cl = factor(trainData$Exited), k = 3, prob = TRUE)
testData$prob <- NULL
modeloknn <- knn(trainData, testData, cl = factor(trainData$Exited), k = 3, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
testData$prob <- NULL
modeloknn <- knn(trainData[,-11], testData[,-11], cl = factor(trainData$Exited), k = 3, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
testData$prob <- NULL
modeloknn <- knn(trainData, testData, cl = factor(trainData$Exited), k = 5, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
auc(curva_roc)
testData$prob <- NULL
modeloknn <- knn(trainData, testData, cl = factor(trainData$Exited), k = 1, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
#plot(curva_roc)
auc(curva_roc)
testData$prob <- NULL
modeloknn <- knn(trainData, testData, cl = factor(trainData$Exited), k = 20, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
auc(curva_roc)
train <- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
test <- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
View(train)
cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)))
testData$prob <- NULL
modeloknn <- knn(trainData[,-11], testData[,-11], cl = factor(trainData$Exited), k = 20, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
auc(curva_roc)
modeloknn %>% as.character() %>% as.numeric()
testData$prob <- NULL
modeloknn <- knn(trainData[,-11], testData[,-11], cl = factor(trainData$Exited), k = 1, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
#plot(curva_roc)
auc(curva_roc)
modeloknn <- knn(trainData[,-11], testData, cl = factor(trainData$Exited), k = 1, prob = TRUE)
testData$prob <- NULL
modeloknn <- knn(trainData[,-11], testData, cl = factor(trainData$Exited), k = 1, prob = TRUE)
modeloknn <- knn(trainData[,-10], testData[,-10], cl = factor(trainData$Exited), k = 1, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
auc(curva_roc)
testData$prob <- NULL
modeloknn <- knn(trainData[,-10], testData[,-10], cl = factor(trainData$Exited), k = 3, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
#plot(curva_roc)
auc(curva_roc)
testData$prob <- NULL
modeloknn <- knn(trainData[,-10], testData[,-10], cl = factor(trainData$Exited), k = 20, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
#plot(curva_roc)
auc(curva_roc)
clasetrain <- factor(trainData$Exited)
clasetest <- factor(testData$Exited)
testData <- testData %>% scale()
testData <- testData %>% scale()
modeloknn <- knn(trainData[,-10], testData[,-10], cl = clasetrain, k = 20, prob = TRUE)
testData$prob <- NULL
clasetrain <- factor(trainData$Exited)
clasetest <- factor(testData$Exited)
testData <- testData %>% scale()
testData$prob <- NULL
trainData <- data[sample,]
testData <- data[-sample,]
testData$prob <- NULL
clasetrain <- factor(trainData$Exited)
clasetest <- factor(testData$Exited)
trainData <- trainData %>% scale()
testData <- testData %>% scale()
modeloknn <- knn(trainData[,-10], testData[,-10], cl = clasetrain, k = 20, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
View(testData)
trainData <- data[sample,]
testData <- data[-sample,]
testData <- sapply(testData, scale)
trainData <-  sapply(trainData, scale)
testData <- sapply(testData, scale)
testData <- sapply(testData, scale)
modeloknn <- knn(trainData[,-10], testData[,-10], cl = clasetrain, k = 20, prob = TRUE)
trainData <- data[sample,]
testData <- data[-sample,]
trainData <-  lapply(trainData, scale)
trainData <- data[sample,]
trainData <-  apply(trainData, 1, scale)
trainData <- data[sample,]
trainData <-  tapply(trainData, scale)
trainData <-  sacle(trainData)
trainData <-  scale(trainData)
trainData <- data[sample,]
trainData <-  scale(trainData) %>% data.frame()
View(trainData)
trainData <- data[sample,]
testData <- data[-sample,]
clasetrain <- factor(trainData$Exited)
clasetest <- factor(testData$Exited)
trainData <-  scale(trainData) %>% data.frame()
testData <- scale(testData) %>% data.frame()
modeloknn <- knn(trainData[,-10], testData[,-10], cl = clasetrain, k = 20, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
clasetest %>% as.character() %>% as.numeric()
testData$Exited <- clasetest %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
auc(curva_roc)
plot(curva_roc)
testData$prob <- NULL
clasetrain <- factor(trainData$Exited)
clasetest <- factor(testData$Exited)
trainData <-  scale(trainData) %>% data.frame()
testData <- scale(testData) %>% data.frame()
modeloknn <- knn(trainData[,-10], testData[,-10], cl = clasetrain, k = 40, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
testData$Exited <- clasetest %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
testData$prob <- NULL
clasetrain <- factor(trainData$Exited)
clasetest <- factor(testData$Exited)
trainData <-  scale(trainData) %>% data.frame()
testData <- scale(testData) %>% data.frame()
modeloknn <- knn(trainData[,-10], testData[,-10], cl = clasetrain, k = 15, prob = TRUE)
testData$prob <- modeloknn %>% as.character() %>% as.numeric()
testData$Exited <- clasetest %>% as.character() %>% as.numeric()
curva_roc <- roc(Exited ~ prob, data = testData)
plot(curva_roc)
auc(curva_roc)
